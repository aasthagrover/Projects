{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "from workalendar.usa import Massachusetts\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "path1 ='/Users/Shuxian/Documents/CSYE7390-Spring2016/CY2014 COB Interval data 1'# use your path\n",
    "path2 =r'/Users/Shuxian/Documents/CSYE7390-Spring2016/CY2014 COB Interval data 2'\n",
    "def readCSV(path,name):\n",
    "    rowfile = pd.read_csv(path + \"/\"+name)\n",
    "    return rowfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savefile(path,name):\n",
    "    if not os.path.exists(path+\"/screwed/\"):\n",
    "        os.makedirs(path+\"/screwed/\")\n",
    "    newdata.to_csv(path+\"/screwed/\"+name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getfilelist(path):\n",
    "    filelist=[]\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".csv\"):\n",
    "            filelist.append(file)\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist1=getfilelist(path1)\n",
    "filelist2=getfilelist(path2)\n",
    "#filelist3 = getfilelist(path3)\n",
    "files=filelist1+filelist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2014</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2014</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2014</td>\n",
       "      <td>15</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/04/2014</td>\n",
       "      <td>27</td>\n",
       "      <td>-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/05/2014</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  TMAX  TMIN\n",
       "0  01/01/2014    29    14\n",
       "1  01/02/2014    26     3\n",
       "2  01/03/2014    15    -9\n",
       "3  01/04/2014    27   -16\n",
       "4  01/05/2014    37     8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp= pd.read_csv('/Users/Shuxian/Documents/CSYE7390-Spring2016/COB Interval data 2014/temp.csv')\n",
    "temp=temp[0:364]\n",
    "temp=temp[temp.columns[1:4]]\n",
    "\n",
    "tm=[]\n",
    "for s in temp['DATE']:\n",
    "    s=str(s)\n",
    "    s=datetime.datetime.strptime(s, '%Y%m%d').strftime('%m/%d/%Y')\n",
    "    tm.append(s)\n",
    "temp['Date']=tm\n",
    "\n",
    "temp.drop('DATE', axis=1, inplace=True)\n",
    "temp=temp[['Date', 'TMAX', 'TMIN']]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build date preprocessing function\n",
    "def clean(path,file):\n",
    "#read file\n",
    "    test=readCSV(path,file)\n",
    "#drop channel    \n",
    "    test.drop('Channel', axis=1, inplace=True)\n",
    "#fill N/A with 0 and drop duplicates\n",
    "    test.fillna(0, inplace=True)\n",
    "    test=test.drop_duplicates()\n",
    "    \n",
    "#Add Day, Month columns  \n",
    "    daylist=[]\n",
    "    monthlist=[]\n",
    "    year=0\n",
    "    for date in test['Date']:\n",
    "        date=datetime.datetime.strptime(date, '%m/%d/%Y')\n",
    "#        date=parse(date)\n",
    "        daylist.append(date.day)\n",
    "        monthlist.append(date.month)\n",
    "        year=date.year\n",
    "    test['Day']=daylist\n",
    "    test['Month']=monthlist\n",
    "#Tracking workingday and holiday\n",
    "    cal = Massachusetts()\n",
    "#holidays = cal.holidays(year)\n",
    "    bl=[]\n",
    "    week=[]\n",
    "    for date in test['Date']:\n",
    "        date=parse(date)\n",
    "        bl.append(cal.is_holiday(date))\n",
    "        week.append(cal.is_working_day(date))\n",
    "    test['Holiday'] = bl\n",
    "    test['Workingday']=week\n",
    "#groupby columns by sum\n",
    "    test=test.groupby(['Account','Date','Day','Month','Workingday','Holiday','Units']).mean()*test.groupby(['Account','Date','Day','Month','Workingday','Holiday','Units']).count()\n",
    "    test.reset_index(level = ['Account','Date','Day','Month','Workingday','Holiday','Units'], inplace = True)\n",
    "#Calculate hourly rates\n",
    "    time1=datetime.datetime.strptime(test.columns[8], '%H:%M')\n",
    "    time2=datetime.datetime.strptime(test.columns[7], '%H:%M')\n",
    "    timediff=time1-time2\n",
    "    num=datetime.timedelta(hours=1)/timediff\n",
    "\n",
    "    for i in range(24):\n",
    "        test[i+1]=np.mean(test[test.columns[7+num*i:(7+num)+num*i]],axis=1)\n",
    "    test=test.drop(test.columns[7:(7+num)+num*23],axis=1,inplace=False)\n",
    "#Transpose table    \n",
    "    test = test.reset_index(drop=True)\n",
    "    \n",
    "    results=[]\n",
    "    for date in test['Date'].unique():\n",
    "        perday=test[test['Date']==date]\n",
    "        a=perday[perday.columns[7:31]]\n",
    "        b=a.transpose()\n",
    "        b.reset_index(level =0, inplace = True)\n",
    "        header=['Hour','Power Factor','kVARh','kWh']\n",
    "        b.columns = header\n",
    "        b=b[header]\n",
    "        arest=perday[perday.columns[0:6]]\n",
    "        result = pd.concat([arest, b], axis=1)\n",
    "        result.fillna(method='ffill', inplace=True)\n",
    "        result.fillna(method='bfill', inplace=True)\n",
    "        results.append(result)\n",
    "        \n",
    "    results = pd.concat(results)\n",
    "    results=results.reset_index(drop=True)\n",
    "    \n",
    "#    newdt = results.merge(temp, on='Date', how='left')\n",
    "# Get Category column\n",
    "    if 'COB' in file:\n",
    "        pos=file.find('-')\n",
    "        nm=file[pos+1:pos+5]\n",
    "        if '.' in nm:\n",
    "            nm = nm.replace(\".\", \"\")\n",
    "            results['Category']=nm\n",
    "        results['Category']=nm\n",
    "    else:\n",
    "        nm=file.partition(' ')[0]\n",
    "        results['Category']=nm\n",
    "#save    \n",
    "    if not os.path.exists(path+\"/screwed/\"):\n",
    "        os.makedirs(path+\"/screwed/\")\n",
    "    results.to_csv(path+\"/screwed/\"+file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for file in filelist1:\n",
    "    clean(path1, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path3='/Users/Shuxian/Documents/CSYE7390-Spring2016/CY2014 COB Interval data 1/done'\n",
    "path4 ='/Users/Shuxian/Documents/CSYE7390-Spring2016/CY2014 COB Interval data 2/done'\n",
    "mfiles=getfilelist(path3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdt=[]\n",
    "for file in mfiles:\n",
    "    newfile = pd.read_csv(path3 + \"/\"+file)\n",
    "    newfile = newfile.reset_index(drop=True)\n",
    "    newdt.append(newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdt=pd.concat(newdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdt=newdt.reset_index(drop=True)\n",
    "newdt.to_csv(path3+'/mergedata2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge1= pd.read_csv(path3 + '/mergedata1.csv')\n",
    "merge2=pd.read_csv(path4 + '/mergedata2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finalmerged=pd.concat([merge1,merge2])\n",
    "finalmerged=finalmerged.reset_index(drop=True)\n",
    "finalmerged.to_csv('/Users/Shuxian/Documents/CSYE7390-Spring2016/COB Interval data 2014/finalmerge.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
